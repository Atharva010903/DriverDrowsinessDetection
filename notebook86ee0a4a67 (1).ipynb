{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10411257,"sourceType":"datasetVersion","datasetId":6452159}],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.applications import InceptionV3, ResNet50, DenseNet201\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout, Input, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:21:36.597341Z","iopub.execute_input":"2025-03-06T19:21:36.597637Z","iopub.status.idle":"2025-03-06T19:21:48.129750Z","shell.execute_reply.started":"2025-03-06T19:21:36.597616Z","shell.execute_reply":"2025-03-06T19:21:48.128967Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"batchsize = 8\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255, rotation_range=0.2, shear_range=0.2, zoom_range=0.2,\n    width_shift_range=0.2, height_shift_range=0.2, validation_split=0.2)\n\ntrain_data = train_datagen.flow_from_directory(\n    '/kaggle/input/mydata/train_data/train_data',\n    target_size=(80, 80), batch_size=batchsize, class_mode='categorical', subset='training')\n\nvalidation_data = train_datagen.flow_from_directory(\n    '/kaggle/input/mydata/train_data/train_data',\n    target_size=(80, 80), batch_size=batchsize, class_mode='categorical', subset='validation')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_data = test_datagen.flow_from_directory(\n    '/kaggle/input/mydata/test_data/test_data',\n    target_size=(80, 80), batch_size=batchsize, class_mode='categorical')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:22:16.712597Z","iopub.execute_input":"2025-03-06T19:22:16.713132Z","iopub.status.idle":"2025-03-06T19:22:55.401793Z","shell.execute_reply.started":"2025-03-06T19:22:16.713107Z","shell.execute_reply":"2025-03-06T19:22:55.400919Z"}},"outputs":[{"name":"stdout","text":"Found 54336 images belonging to 2 classes.\nFound 13583 images belonging to 2 classes.\nFound 16979 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def build_model(base_model):\n    base_model = base_model(include_top=False, weights='imagenet', input_tensor=Input(shape=(80, 80, 3)))\n    x = Flatten()(base_model.output)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(2, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=x)\n    for layer in base_model.layers:\n        layer.trainable = False\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:23:38.967487Z","iopub.execute_input":"2025-03-06T19:23:38.967813Z","iopub.status.idle":"2025-03-06T19:23:38.972890Z","shell.execute_reply.started":"2025-03-06T19:23:38.967788Z","shell.execute_reply":"2025-03-06T19:23:38.971944Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"models = {\n    'InceptionV3': build_model(InceptionV3),\n    'ResNet50': build_model(ResNet50),\n    'DenseNet201': build_model(DenseNet201)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:23:58.144021Z","iopub.execute_input":"2025-03-06T19:23:58.144342Z","iopub.status.idle":"2025-03-06T19:24:09.027207Z","shell.execute_reply.started":"2025-03-06T19:23:58.144314Z","shell.execute_reply":"2025-03-06T19:24:09.026577Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"best_model_name = None\nbest_val_acc = 0\nbest_model = None\n\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    checkpoint = ModelCheckpoint(f'/kaggle/working/{name}.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=3)\n    earlystop = EarlyStopping(monitor='val_loss', patience=7, verbose=3, restore_best_weights=True)\n    learning_rate = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=3)\n    callbacks = [checkpoint, earlystop, learning_rate]\n    \n    model.fit(train_data, steps_per_epoch=train_data.samples//batchsize, validation_data=validation_data,\n              validation_steps=validation_data.samples//batchsize, callbacks=callbacks, epochs=5)\n    \n    loss_val, acc_val = model.evaluate(validation_data)  \n\n    print(f\"Validation Accuracy for {name}: {acc_val}\")\n    \n    if acc_val > best_val_acc:\n        best_val_acc = acc_val\n        best_model_name = name\n        best_model = model\n\nprint(f\"Best model: {best_model_name} with accuracy: {best_val_acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T20:24:29.757689Z","iopub.execute_input":"2025-03-06T20:24:29.758047Z","execution_failed":"2025-03-06T21:22:26.172Z"}},"outputs":[{"name":"stdout","text":"Training InceptionV3...\nEpoch 1/5\n\u001b[1m6791/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9338 - loss: 0.1732\nEpoch 1: val_loss improved from inf to 0.23777, saving model to /kaggle/working/InceptionV3.weights.h5\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 40ms/step - accuracy: 0.9338 - loss: 0.1732 - val_accuracy: 0.9083 - val_loss: 0.2378 - learning_rate: 0.0010\nEpoch 2/5\n\nEpoch 2: val_loss improved from 0.23777 to 0.03762, saving model to /kaggle/working/InceptionV3.weights.h5\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0376 - learning_rate: 0.0010\nEpoch 3/5\n\u001b[1m6789/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9340 - loss: 0.1672\nEpoch 3: val_loss did not improve from 0.03762\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 31ms/step - accuracy: 0.9340 - loss: 0.1672 - val_accuracy: 0.8906 - val_loss: 0.2609 - learning_rate: 0.0010\nEpoch 4/5\n\nEpoch 4: val_loss did not improve from 0.03762\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.1276 - learning_rate: 0.0010\nEpoch 5/5\n\u001b[1m6789/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9368 - loss: 0.1628\nEpoch 5: val_loss did not improve from 0.03762\n\nEpoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 31ms/step - accuracy: 0.9368 - loss: 0.1628 - val_accuracy: 0.9048 - val_loss: 0.2655 - learning_rate: 0.0010\nRestoring model weights from the end of the best epoch: 2.\n\u001b[1m1698/1698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9097 - loss: 0.2324\nValidation Accuracy for InceptionV3: 0.9065743684768677\nTraining ResNet50...\nEpoch 1/5\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4995 - loss: 0.6932\nEpoch 1: val_loss improved from inf to 0.69307, saving model to /kaggle/working/ResNet50.weights.h5\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 31ms/step - accuracy: 0.4995 - loss: 0.6932 - val_accuracy: 0.5060 - val_loss: 0.6931 - learning_rate: 0.0010\nEpoch 2/5\n\nEpoch 2: val_loss did not improve from 0.69307\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2857 - val_loss: 0.6991 - learning_rate: 0.0010\nEpoch 3/5\n\u001b[1m6791/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5011 - loss: 0.6932\nEpoch 3: val_loss did not improve from 0.69307\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 30ms/step - accuracy: 0.5011 - loss: 0.6932 - val_accuracy: 0.5061 - val_loss: 0.6931 - learning_rate: 0.0010\nEpoch 4/5\n\nEpoch 4: val_loss did not improve from 0.69307\n\nEpoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.1429 - val_loss: 0.7001 - learning_rate: 0.0010\nEpoch 5/5\n\u001b[1m6791/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5066 - loss: 0.6931\nEpoch 5: val_loss did not improve from 0.69307\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 30ms/step - accuracy: 0.5066 - loss: 0.6931 - val_accuracy: 0.5060 - val_loss: 0.6931 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n\u001b[1m1698/1698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.5102 - loss: 0.6930\nValidation Accuracy for ResNet50: 0.5059265494346619\nTraining DenseNet201...\nEpoch 1/5\n\u001b[1m6791/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9467 - loss: 0.1370\nEpoch 1: val_loss improved from inf to 0.23611, saving model to /kaggle/working/DenseNet201.weights.h5\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 35ms/step - accuracy: 0.9467 - loss: 0.1370 - val_accuracy: 0.9146 - val_loss: 0.2361 - learning_rate: 0.0010\nEpoch 2/5\n\nEpoch 2: val_loss improved from 0.23611 to 0.00030, saving model to /kaggle/working/DenseNet201.weights.h5\n\u001b[1m6792/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 2.9804e-04 - learning_rate: 0.0010\nEpoch 3/5\n\u001b[1m4889/6792\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 27ms/step - accuracy: 0.9519 - loss: 0.1289","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Save best model\nbest_model.save('/kaggle/working/best_model.h5')\nprint(\"Best model saved successfully\")\n\n# Verify file\nif os.path.exists('/kaggle/working/best_model.h5'):\n    print(\"File exists at:\", os.getcwd() + '/best_model.h5')\n\n!zip -r zip_folder.zip /kaggle/working/best_model.h5\nfrom IPython.display import FileLink\nFileLink('zip_folder.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T20:10:39.338917Z","iopub.execute_input":"2025-03-06T20:10:39.339558Z","iopub.status.idle":"2025-03-06T20:10:45.253406Z","shell.execute_reply.started":"2025-03-06T20:10:39.339530Z","shell.execute_reply":"2025-03-06T20:10:45.252346Z"}},"outputs":[{"name":"stdout","text":"Best model saved successfully\nFile exists at: /kaggle/working/best_model.h5\n  adding: kaggle/working/best_model.h5 (deflated 16%)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/zip_folder.zip","text/html":"<a href='zip_folder.zip' target='_blank'>zip_folder.zip</a><br>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}